---
title:  "AI is not 'slow kind of country'"
date:   2023-10-17 12:00:56 +0700
categories: ai
tags: ai
tagline: ""
header:
  overlay_image: assets/ai-transformation/ai_adoption.jpeg
  overlay_filter: 0.5
  teaser: assets/ai-transformation/ai_adoption.jpeg
---

Back in business - after dramatic pause and 3 projects behind ðŸ˜€
Below is compilation of 3 small posts from [LinkedIn](https://www.linkedin.com/in/skovalev/recent-activity/all/)


### Context 
- Red queen race
- AI adoption
- LLM is junior


## The Red Queen's AI Race
In the realm of tech, AI adoption feels reminiscent of the Red Queen's race from "Alice in Wonderland" - indeed, we're no longer in 'a slow sort of country!'

![red queen race - AI plans](/assets/ai-transformation/red_queen_race.jpeg)

**Participate**
- Every individual in an organization must now harness the capabilities of AI tools and integrate them into their daily tasks.
- In the upcoming month, the focus should shift to crafting in-house AI solutions to refine and elevate processes.
- And by the next quarter, it's time to weave AI seamlessly into product lines, take the helm of industry-wide AI initiatives, and seek inspiration from platforms like ChatGPT for a fresh wave of ideas!ðŸ˜€



## Embracing AI
Many of us have dabbled with tools like ChatGPT, StableDiffusion, and other AI utilities. However, integrating AI at an enterprise or departmental level or weaving it into an application remains a challenging feat. The absence of a one-size-fits-all AI framework does complicate matters. Currently, AI projects often feel more akin to exploratory research than traditional software development. Presented here is a methodical approach to ease AI adoption. It's not a rigid framework, but a flexible strategy to consider.

![AI Adoption Incrementally](/assets/ai-transformation/ai_adoption.jpeg)

**The AI Adoption Approach**:
1. **Identify Potential**: Draft a list of use cases that can benefit from AI acceleration or enablement.
2. **Three Pillars of Focus**: For each use case, center your strategy around three primary pillars: data, algorithm, and user experience (UX).
   - **Data**: This encompasses the information that will be employed to train or underpin the AI, establishing it as a strategic asset.
   - **Algorithm**: Instead of chasing the latest AI innovations (given the inundated state of AI news feeds), select a reliable, time-tested algorithm.
   - **UX**: Develop AI-backed widgets for integration into your portal or application. Always have an administrative interface or dashboard in place to monitor performance and gauge user engagement.
3. **Quality over Quickness**: Prior to rolling out any solution (even to early adopters), it's crucial to vet its reliability. Due to the unpredictable nature of AI, it's advisable to employ a "red team" or an independent group to test and challenge the system's security and reliability.

**The Key**: Begin with simplicity. A common mistake is to invest all your resources into perfecting one pillar at the outset. Such an approach often stalls projects. Instead, view each pillar as a container that you gradually fill over successive development cycles. For the first cycle, pour a modest amount into each container. Once you have a functioning system in place - which is often the hardest part organizationally - continue to incrementally enhance each pillar over time.

## LLM is junior
While general large language models (LLM) like Claude2, Bard, ChatGPT, and others are incredibly versatile, it's essential to recognize that their performance on niche domain-specific tasks may not always match an expert's acumen. Instead of expecting senior-level expertise, it might be more realistic to anticipate competence equivalent to a junior or mid-level professional. Strategies to maximize LLM effectiveness include:
- Simplifying tasks or dividing them into more manageable sub-tasks.
- Giving illustrative examples for better understanding.
- Actively ensuring the results' accuracy.

![llm is junior](/assets/ai-transformation/llm_is_junior.jpeg)

**Verification Techniques:**
- Integrate a verification step within your prompt. If the model's response doesn't satisfy the verification criteria, request reconsideration.
- Design the LLM interaction to include multiple steps or loops for self-checks and validation.
- Engage a secondary model or system with a distinct prompt to corroborate the initial LLM's responses.


## Book is book, not a knowledge
[DIKW pyramid](https://en.wikipedia.org/wiki/DIKW_pyramid)
> The DIKW pyramid, also known variously as the DIKW hierarchy, wisdom hierarchy, knowledge hierarchy, information hierarchy, information pyramid, and the data pyramid, refers loosely to a class of models for representing purported structural and/or functional relationships between data, information, knowledge, and wisdom. "Typically information is defined in terms of data, knowledge in terms of information, and wisdom in terms of knowledge".The DIKW acronym has worked into the rotation from knowledge management. It demonstrates how the deep understanding of the subject emerges, passing through four qualitative stages: "D" â€“ data, "I" â€“ information, "K" â€“ knowledge and "W" â€“ wisdom

![book is a book](/assets/ai-transformation/book_is_a_book.png)

In the world of Knowledge Management, let's break down the differences between data, information, and knowledge in a more casual way. A common misunderstanding these days is thinking that just tossing documents into a digital storage bin and using fancy Retrieval Augmented Generation (RAG) with Large Language Models (LLM) will magically transform your system into a Knowledge Management powerhouse. Nope, it doesn't work that way â€“ you're still squarely in the realm of Information Management.

To put it simply, when it comes to knowledge, think of it as __"active"__ compared to information, which is more __"passive"__.
Now, let's expand on this with some relatable examples:

**Knowledge Gets Things Done:**
Knowledge isn't just knowing stuff; it's about having the know-how to get things done. Imagine you have a text with an algorithm that you understand and can execute. That text becomes knowledge because you can put it into action. You're like a problem-solving wizard with that knowledge!

**Information is Like Clues:**
But, if the same text lands in front of someone who doesn't have the magic skills to run that algorithm, it's just information. It's like giving them a bunch of clues, but they don't quite know how to use them.

**Data is the Raw Material:**
Now, picture this: someone who not only can't execute the algorithm but also doesn't understand the language of that text. For them, it's not even information; it's just raw data. It's like staring at a jumble of characters without a clue.
The point here is that in Knowledge Management, we're not just about collecting heaps of data or storing loads of information. It's about making sure people can take that info and do something useful with it. True Knowledge Management is about turning data into actionable information and eventually into practical know-how that drives results. It's like having the right tools in your toolbox â€“ it's not about how many you have, but how well you can use them to build something amazing.


